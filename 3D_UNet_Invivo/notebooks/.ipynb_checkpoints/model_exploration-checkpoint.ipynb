{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model and predicting patients\n",
    "\n",
    "Each of the trained models can be restored from their checkpoints and used for evaluation or prediction, thanks to `tf.estimator.Estimator` API.\n",
    "\n",
    "This can be done with `main.py` using the following call:\n",
    "```\n",
    "python src/main.py -model_dir models/base_model -mode predict - pred_ix 0 1 2 3 4 5 6 7 8 9\n",
    "```\n",
    "\n",
    "Alternatively predicting only the 2nd and 7th patient is as simple as:\n",
    "```\n",
    "python src/main.py -model_dir models/base_model -mode predict - pred_ix 1 6\n",
    "```\n",
    "\n",
    "## Examining predictions\n",
    "\n",
    "Here we already predicted all patients with all 3 models (`base_model`, `base_model_no_bn`, `deeper_model`) both on the original test scans and the resized (128 x 128) ones.\n",
    "\n",
    "We'll load some of these and visualise them next to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/amos/3D_UNet_Multi_Class/')\n",
    "\n",
    "from src.data_utils import Dataset\n",
    "from src.input_fn import input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model dirs\n",
    "base_model_dir = '../models/base_model/'\n",
    "#deeper_model_dir = '../models/deeper_model/'\n",
    "\n",
    "# predictions of base model on resized test set (128x128)\n",
    "preds_file = open(os.path.join(base_model_dir, 'preds.npy'),'rb')\n",
    "bm_resized_preds = pickle.load(preds_file)\n",
    "\n",
    "\n",
    "#print(bm_resized_preds)\n",
    "\n",
    "# predictions of deeper model on resized test set (128x128)\n",
    "#preds_file = open(os.path.join(deeper_model_dir, 'preds.npy'),'rb')\n",
    "#dm_resized_preds = pickle.load(preds_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse src.data_utils.Dataset to visualise\n",
    "\n",
    "We can load a saved test dataset and use its plotting code to visualise truth vs prediction.\n",
    "\n",
    "By replacing the scans in each patient with the original ground truth segmentation (left) and the original segmentation array with the predictions, we can easily plot anyone's prediction vs real segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions from base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = bm_resized_preds\n",
    "# test_dataset_resized = Dataset.load_dataset('../data/processed/test_dataset_resized.pckl')\n",
    "# for i, p in enumerate(test_dataset_resized.patients.values()):\n",
    "#     # restrict plots to middle section, i.e. interesting part\n",
    "#     p.scans = preds[i]['truth'][1]\n",
    "#     p.segs = preds[i]['classes'][1]\n",
    "#     p.preprocessed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bm_resized_preds\n",
    "test_dataset_resized = Dataset.load_dataset('../data/processed/test_dataset_resized.pckl')\n",
    "\n",
    "scans = preds[0]['truth'][0]\n",
    "segs = preds[0]['classes'][0]\n",
    "\n",
    "\n",
    "\n",
    "# for i, p in enumerate(test_dataset_resized.patients.values()):\n",
    "#     # restrict plots to middle section, i.e. interesting part\n",
    "    \n",
    "#     pred = preds[0]['truth'][0]\n",
    "#     print(pred)\n",
    "#     p.scans = preds[i]['truth'][0]\n",
    "#     p.segs = preds[i]['classes'][0]\n",
    "#     p.preprocessed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset_resized.patients[test_dataset_resized.patient_ids[0]].patient_tile_scans2()\n",
    "\n",
    "# # note the target is now a one-hot tensor, we just show the class that we define in def tile_scans or def anim_scans\n",
    "# patient_id = train_dataset.patient_ids[0]\n",
    "# train_dataset.patients[patient_id].patient_tile_scans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_resized.patients[test_dataset_resized.patient_ids[0]].patient_anim_scans2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_resized.patients[test_dataset_resized.patient_ids[0]].patient_tile_scans2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions from deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dm_resized_preds\n",
    "test_dataset_resized = Dataset.load_dataset('../data/processed/test_dataset_resized.pckl')\n",
    "for i, p in enumerate(test_dataset_resized.patients.values()):\n",
    "    # restrict plots to middle section, i.e. interesting part\n",
    "    p.scans = preds[i]['truth'][9:18]\n",
    "    p.seg = preds[i]['classes'][9:18]\n",
    "    p.preprocessed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_resized.patients[test_dataset_resized.patient_ids[7]].patient_tile_scans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_resized.patients[test_dataset_resized.patient_ids[9]].patient_tile_scans()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
