{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "%pylab inline\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data,cmaps,label_names=None):\n",
    "    data_shape = np.array(data).shape\n",
    "    numImageTypes = data_shape[0]\n",
    "    numImageSets = data_shape[1]\n",
    "    print(numImageTypes,numImageSets)\n",
    "    fig = plt.figure(figsize=(3*numImageTypes,3*numImageSets))\n",
    "    for i in range(numImageSets):\n",
    "        for j in range(numImageTypes):\n",
    "            ax = plt.subplot(numImageSets, numImageTypes,i*numImageTypes + j+1)\n",
    "            if not label_names==None:\n",
    "                ax.set_title(label_names[j])\n",
    "            plt.axis('off')\n",
    "            img = plt.imshow(data[j][i])\n",
    "            img.set_cmap(cmaps[j])\n",
    "    plt.show()\n",
    "\n",
    "def plot_prepared_data(prepared_data,labels,label_names=None):\n",
    "    cmaps = ['gray','gist_ncar']\n",
    "    data = [prepared_data[0][:,:,:,0], one_hot_decoding(prepared_data[1],labels)]\n",
    "    data_shape = np.array(data).shape\n",
    "    numImageTypes = data_shape[0]\n",
    "    numImageSets = data_shape[1]\n",
    "    print(numImageTypes,numImageSets)\n",
    "    fig = plt.figure(figsize=(3*numImageTypes,3*numImageSets))\n",
    "    for i in range(numImageSets):\n",
    "        for j in range(numImageTypes):\n",
    "            ax = plt.subplot(numImageSets, numImageTypes,i*numImageTypes + j+1)\n",
    "            if not label_names==None:\n",
    "                ax.set_title(label_names[j])\n",
    "            plt.axis('off')\n",
    "            img = plt.imshow(data[j][i])\n",
    "            img.set_cmap(cmaps[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import utils\n",
    "def fix_labels2(label_images,labels):\n",
    "    encoded = []\n",
    "    numLabels = len(labels)\n",
    "    for img in label_images:\n",
    "        img2 = numpy.zeros_like(img)\n",
    "        for i,label in enumerate(labels):\n",
    "            img2 = np.where(img==label, i+1, img2)\n",
    "        encoded.append(img2)\n",
    "    return encoded\n",
    "def fix_labels(img,labels):\n",
    "    img2 = numpy.zeros_like(img)\n",
    "    for i,label in enumerate(labels):\n",
    "        img2 = np.where(img==label, i+1, img2)        \n",
    "    return img2\n",
    "        \n",
    "def one_hot_encoding(label_images,numLabels):\n",
    "    encoded = []\n",
    "    for img in label_images:\n",
    "        original_shape = img.shape\n",
    "        #print(original_shape)\n",
    "        #print(numLabels)\n",
    "        img2= utils.to_categorical(img.flatten(), numLabels)\n",
    "        img2 = np.reshape(img2, (original_shape[0],original_shape[1],numLabels))\n",
    "        encoded.append(img2)\n",
    "        #print(numLabels,img2.shape)\n",
    "    return encoded\n",
    "\n",
    "        \n",
    "def one_hot_decoding(encodings,labels):\n",
    "    decoded = []\n",
    "    for img in encodings:\n",
    "        if (len(img.shape)!=3):\n",
    "            print(\"ERROR: wrong shape\")\n",
    "        original_shape = (img.shape[0],img.shape[1])\n",
    "        img2 = numpy.zeros(original_shape)\n",
    "        \n",
    "        #print(original_shape)\n",
    "        for i, label in enumerate(labels):\n",
    "            img2 += np.array(img)[:,:,i+1]*label\n",
    "        decoded.append(img2)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, GlobalMaxPool2D,concatenate, add\n",
    "#from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "#from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "#from tensorflow.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "#from tensorflow.keras.layers.merge import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return Conv2DTranspose(filters, kernel_size, strides=2, padding=padding)#strides=strides,\n",
    "\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return UpSampling2D(kernel_size)\n",
    "\n",
    "\n",
    "def conv2d_block(\n",
    "    inputs, \n",
    "    use_batch_norm=True, \n",
    "    dropout=0.3, \n",
    "    filters=16, \n",
    "    kernel_size=(3,3), \n",
    "    activation='relu', \n",
    "    kernel_initializer='he_normal', \n",
    "    padding='same'):\n",
    "    \n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (inputs)\n",
    "    if use_batch_norm:\n",
    "        c = BatchNormalization()(c)\n",
    "    #if dropout > 0.0:\n",
    "    c = Dropout(dropout)(c)\n",
    "    c = Conv2D(filters, kernel_size, activation=activation, kernel_initializer=kernel_initializer, padding=padding) (c)\n",
    "    if use_batch_norm:\n",
    "        c = BatchNormalization()(c)\n",
    "    return c\n",
    "\n",
    "def normal_unet(\n",
    "    inputs,\n",
    "    num_classes=1,\n",
    "    num_channels=1,\n",
    "    use_batch_norm=True, \n",
    "    upsample_mode='deconv', #'simple', #  'deconv' or \n",
    "    use_dropout_on_upsampling=False, \n",
    "    dropout=0.15, \n",
    "    dropout_change_per_layer=0.0,\n",
    "    filters=16,\n",
    "    num_layers=4,\n",
    "    output_activation='softmax'): # 'sigmoid' or 'softmax'\n",
    "    print(\"--------create unet\")\n",
    "    if upsample_mode=='deconv':\n",
    "        upsample=upsample_conv\n",
    "    else:\n",
    "        upsample=upsample_simple\n",
    "    keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "    # Build U-Net model\n",
    "    #inputs = Input( shape=(num_channels,) +tuple(input_shape), name=\"input\") #\n",
    "    x = inputs   \n",
    "\n",
    "    down_layers = []\n",
    "    for l in range(num_layers):\n",
    "        x = conv2d_block(inputs=x, filters=filters, use_batch_norm=use_batch_norm, dropout=dropout)\n",
    "        print(\" -v- \",filters)\n",
    "        down_layers.append(x)\n",
    "        x = MaxPooling2D((2, 2)) (x)\n",
    "        dropout += dropout_change_per_layer\n",
    "        filters = filters*2 # double the number of filters with each layer\n",
    "\n",
    "    x = conv2d_block(inputs=x, filters=filters, use_batch_norm=use_batch_norm, dropout=dropout)\n",
    "    print(\" -+- \",filters)\n",
    "    print(down_layers)\n",
    "\n",
    "    if not use_dropout_on_upsampling:\n",
    "        dropout = 0.0\n",
    "        dropout_change_per_layer = 0.0\n",
    "\n",
    "    for conv in reversed(down_layers):        \n",
    "        filters //= 2 # decreasing number of filters with each layer \n",
    "        dropout -= dropout_change_per_layer\n",
    "        x = upsample(filters, (2,2), strides=(2, 2), padding='same') (x)#(2, 2)\n",
    "        print(\" -^- \",filters)\n",
    "        x = tf.keras.layers.concatenate([x, conv],axis=3)\n",
    "        x = conv2d_block(inputs=x, filters=filters, use_batch_norm=use_batch_norm, dropout=dropout)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1),  activation='softmax', name=\"output\") (x)    \n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    print(\"num_classes\",num_classes)\n",
    "    \n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    #print(path)\n",
    "    train_gt = glob.glob(path + \"/*.cso.dcm\")\n",
    "    train_T1 = [ s.replace(\".cso\", \"_T1\") for s in train_gt]\n",
    "    train_T2 = [ s.replace(\".cso\", \"_T2\") for s in train_gt]\n",
    "    train_T2s = [ s.replace(\".cso\", \"_T2s\") for s in train_gt]\n",
    "    train_PD = [ s.replace(\".cso\", \"_PD\") for s in train_gt]\n",
    "    #print(train_gt)\n",
    "    gts = []\n",
    "    t1s = []\n",
    "    t2s = []\n",
    "    t2ss = []\n",
    "    pds = []\n",
    "    for s in train_gt:\n",
    "        ds = pydicom.dcmread(s) \n",
    "        gts.append(ds.pixel_array)\n",
    "    for s in train_T1:\n",
    "        ds = pydicom.dcmread(s) \n",
    "        t1s.append(ds.pixel_array)\n",
    "    for s in train_T2:\n",
    "        ds = pydicom.dcmread(s) \n",
    "        t2s.append(ds.pixel_array)\n",
    "    for s in train_T2s:\n",
    "        ds = pydicom.dcmread(s) \n",
    "        t2ss.append(ds.pixel_array)\n",
    "    for s in train_PD:\n",
    "        ds = pydicom.dcmread(s) \n",
    "        pds.append(ds.pixel_array)\n",
    "    \n",
    "    return t1s,t2s,t2ss,pds,gts\n",
    "\n",
    "def combine_contrasts(contrasts):\n",
    "    contrasts = [np.array(c) for c in contrasts]\n",
    "    #print(\"c\",contrasts[1].shape)\n",
    "    combined_contrasts = np.stack(contrasts,axis=3)\n",
    "    #print(\"d\",combined_contrasts.shape)\n",
    "    return combined_contrasts\n",
    "\n",
    "def prepare_data(path,labels):\n",
    "    print('Labels: '+ str(labels))\n",
    "    t1s,t2s,t2ss,pds,gts = read_data(path)\n",
    "    #print(\"gts:\",np.unique(gts[0]),np.unique(gts[1]))\n",
    "    data_x = combine_contrasts([t1s,t2s,t2ss,pds])\n",
    "    #print(\"e\",train_x.shape,len(labels)+1)\n",
    "    data_y = np.array(one_hot_encoding(fix_labels2(gts,labels),len(labels)+1))#labels,15))#\n",
    "    return data_x,data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLabels = {\"lumen\": 14, \n",
    "             \"intima\":  1 , \n",
    "             \"media\":  2 , \n",
    "             \"AtheromatousCore\":  4 , \n",
    "             \"FibrousTissue\":  3 , \n",
    "             \"calcification\": 13 ,\n",
    "             \"WhiteThrombus\": 6 ,\n",
    "             \"RedThrombus\":  7 ,\n",
    "             \"microvessels\":  11 ,\n",
    "             \"hemorrhage\":  12 ,\n",
    "             \"unknown\":  8 ,\n",
    "             \"inflammation\":  10 ,\n",
    "             \"fibrin+hemorrhage\":  9 ,\n",
    "             \"atheromatous+hemorrhage\":  5 ,\n",
    "             \"background\": 0}\n",
    "id_to_label = {v: k for k, v in allLabels.items()}\n",
    "\n",
    "labels_to_keep = [1,2,5,8,13,14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw'\n",
    "path_train = path + \"/train\"\n",
    "path_eval  = path + \"/eval\"\n",
    "path_test  = path + \"/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [1, 2, 5, 8, 13, 14]\n",
      "Training data:\n",
      "x shape: (512, 512, 4)\n",
      "y shape: (512, 512, 7)\n",
      "-------------------------\n",
      "Labels: [1, 2, 5, 8, 13, 14]\n",
      "Evaluation data:\n",
      "x shape: (512, 512, 4)\n",
      "y shape: (512, 512, 7)\n",
      "-------------------------\n",
      "Test data: \n",
      "Labels: [1, 2, 5, 8, 13, 14]\n",
      "x shape: (512, 512, 4)\n",
      "y shape: (512, 512, 7)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prepare_data(path_train,labels_to_keep)\n",
    "print('Training data:')\n",
    "print(\"x shape:\",train_x[0].shape)\n",
    "print(\"y shape:\",train_y[0].shape)\n",
    "print('-------------------------')\n",
    "\n",
    "\n",
    "\n",
    "eval_x, eval_y = prepare_data(path_eval,labels_to_keep)\n",
    "print('Evaluation data:')\n",
    "print(\"x shape:\",eval_x[0].shape)\n",
    "print(\"y shape:\",eval_y[0].shape)\n",
    "print('-------------------------')\n",
    "\n",
    "print('Test data: ')\n",
    "test_x, test_y = prepare_data(path_test,labels_to_keep)\n",
    "print(\"x shape:\",train_x[0].shape)\n",
    "print(\"y shape:\",train_y[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/anaconda3/envs/thesis/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:923: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (49, 512, 512, 7) (7 channels).\n",
      "  ' channels).')\n",
      "/home/amos/anaconda3/envs/thesis/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py:127: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (49, 512, 512, 7) (7 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "# Creating the training Image and Mask generator\n",
    "image_datagen = ImageDataGenerator(rotation_range=30, horizontal_flip=True, vertical_flip=True)\n",
    "mask_datagen = ImageDataGenerator(rotation_range=30, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# keep the same seed for image and mask generators so that they fit together\n",
    "image_datagen.fit(train_x, augment=True, seed = seed)\n",
    "mask_datagen.fit(train_y, augment=True, seed = seed)\n",
    "\n",
    "x = image_datagen.flow(train_x, batch_size=2,shuffle=True, seed=seed)\n",
    "y = image_datagen.flow(train_y, batch_size=2,shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/anaconda3/envs/thesis/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:923: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (11, 512, 512, 7) (7 channels).\n",
      "  ' channels).')\n",
      "/home/amos/anaconda3/envs/thesis/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py:127: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (11, 512, 512, 7) (7 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "# creating the validation Image and Mask generator\n",
    "image_datagen_val = ImageDataGenerator()\n",
    "mask_datagen_val = ImageDataGenerator()\n",
    "\n",
    "image_datagen_val.fit(eval_x, augment=True, seed = seed)\n",
    "mask_datagen_val.fit(eval_y, augment=True, seed = seed)\n",
    "\n",
    "x_val = image_datagen.flow(eval_x, batch_size=1,shuffle=True, seed=seed)\n",
    "y_val = image_datagen.flow(eval_y, batch_size=1,shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training and validation generator that generate masks and images\n",
    "train_generator = zip(x, y)\n",
    "val_generator = zip(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        k.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return k.mean(k.stack(prec), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = k.sum(k.round(k.clip(y_pred, 0, 1)))\n",
    "    c3 = k.sum(k.round(k.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = k.ones_like(y_true) \n",
    "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
    "    all_positives = k.sum(k.round(k.clip(y_true, 0, 1)))\n",
    "    \n",
    "    recall = true_positives / (all_positives + k.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = k.ones_like(y_true) \n",
    "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    predicted_positives = k.sum(k.round(k.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + k.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def Mean_IOU_tensorflow_1(y_true, y_pred):\n",
    "    nb_classes = k.int_shape(y_pred)[-1]\n",
    "    iou = []\n",
    "    true_pixels = k.argmax(y_true, axis=-1)\n",
    "    pred_pixels = k.argmax(y_pred, axis=-1)\n",
    "    void_labels = k.equal(k.sum(y_true, axis=-1), 0)\n",
    "    for i in range(0, nb_classes): # exclude first label (background) and last label (void)\n",
    "        true_labels = k.equal(true_pixels, i) & ~void_labels\n",
    "        pred_labels = k.equal(pred_pixels, i) & ~void_labels\n",
    "        inter = tf.to_int32(true_labels & pred_labels)\n",
    "        union = tf.to_int32(true_labels | pred_labels)\n",
    "        legal_batches = k.sum(tf.to_int32(true_labels), axis=1)>0\n",
    "        ious = k.sum(inter, axis=1)/k.sum(union, axis=1)\n",
    "        iou.append(k.mean(tf.gather(ious, indices=tf.where(legal_batches)))) # returns average IoU of the same objects\n",
    "    iou = tf.stack(iou)\n",
    "    legal_labels = ~tf.debugging.is_nan(iou)\n",
    "    iou = tf.gather(iou, indices=tf.where(legal_labels))\n",
    "    return k.mean(iou)\n",
    "\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = k.sum(y_true * y_pred)\n",
    "    union = k.sum(y_true + y_pred)\n",
    "    jac = (intersection + 1.) / (union - intersection + 1.)\n",
    "    return k.mean(jac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------create unet\n",
      " -v-  32\n",
      " -v-  64\n",
      " -v-  128\n",
      " -v-  256\n",
      " -+-  512\n",
      "[<tf.Tensor 'batch_normalization_1/cond/Merge:0' shape=(?, 512, 512, 32) dtype=float32>, <tf.Tensor 'batch_normalization_3/cond/Merge:0' shape=(?, 256, 256, 64) dtype=float32>, <tf.Tensor 'batch_normalization_5/cond/Merge:0' shape=(?, 128, 128, 128) dtype=float32>, <tf.Tensor 'batch_normalization_7/cond/Merge:0' shape=(?, 64, 64, 256) dtype=float32>]\n",
      " -^-  256\n",
      " -^-  128\n",
      " -^-  64\n",
      " -^-  32\n",
      "num_classes 7\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 512, 512, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 1184        img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 256)  524544      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 128 131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 128 295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 128 147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 64) 32832       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 64) 36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 32) 8224        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 512, 512, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 512, 512, 7)  231         batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,772,359\n",
      "Trainable params: 7,766,471\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = tf.keras.Input(train_x[0].shape, name='img')\n",
    "model = normal_unet(input_img, filters=32, dropout=0.15,num_classes=len(labels_to_keep)+1,num_channels=4,num_layers=4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-35c255629bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmean_iou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaccard_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMean_IOU_tensorflow_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mskip_target_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_target_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         sample_weights=self.sample_weights)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;31m# Prepare gradient updates and state updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[0;34m(self, outputs, skip_target_indices, targets, sample_weights, masks)\u001b[0m\n\u001b[1;32m    311\u001b[0m         metric_results.extend(\n\u001b[1;32m    312\u001b[0m             self._handle_per_output_metrics(self._per_output_metrics[i], target,\n\u001b[0;32m--> 313\u001b[0;31m                                             output, output_mask))\n\u001b[0m\u001b[1;32m    314\u001b[0m         metric_results.extend(\n\u001b[1;32m    315\u001b[0m             self._handle_per_output_metrics(\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[0;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[1;32m    268\u001b[0m               metric_fn)\n\u001b[1;32m    269\u001b[0m           metric_result = weighted_metric_fn(\n\u001b[0;32m--> 270\u001b[0;31m               y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[1;32m    597\u001b[0m     \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-be12e4cfa349>\u001b[0m in \u001b[0;36mmean_iou\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my_pred_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_int32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup_opt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_SESSION\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m       \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_default_session_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[mean_iou, f1_score, jaccard_coef, Mean_IOU_tensorflow_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usel links: \n",
    "\n",
    "--- EarlyStopping: https://stackoverflow.com/questions/43906048/which-parameters-should-be-used-for-early-stopping                    \n",
    "\n",
    "--- ModelCheckpoint: https://keras.io/api/callbacks/model_checkpoint/\n",
    "\n",
    "--- And: https://keras.io/api/callbacks/early_stopping/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('model-dsExvivo2020-1.h5', monitor='loss',verbose=1, save_best_only=True)\n",
    "results = model.fit_generator(train_generator, validation_data=val_generator,validation_steps=2000, steps_per_epoch=10000,\n",
    "                              epochs=10, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patience: is the epoch where the check will be done to know if the earlystopping chall be applied.\n",
    "#earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "#checkpointer = ModelCheckpoint('model-dsExvivo2020-1.h5', verbose=1, save_best_only=True)\n",
    "#results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=2000, steps_per_epoch=10000,\n",
    "#                              epochs=10, callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation mean_iou values\n",
    "plt.plot(results.history['f1_score'])\n",
    "plt.plot(results.history['val_f1_score'])\n",
    "plt.title('Model F1_score')\n",
    "plt.ylabel('F1_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig('F1_score.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation mean_iou values\n",
    "plt.plot(results.history['jaccard_coef'])\n",
    "plt.plot(results.history['val_jaccard_coef'])\n",
    "plt.title('Model Jaccard Coef')\n",
    "plt.ylabel('Jaccard_coef')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig('Jaccard_coef.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation mean_iou values\n",
    "plt.plot(results.history['Mean_IOU_tensorflow_1'])\n",
    "plt.plot(results.history['val_Mean_IOU_tensorflow_1'])\n",
    "plt.title('Model IOU_tensorflow_1')\n",
    "plt.ylabel('IOU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig('Model_IOU_tensorflow_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation mean_iou values\n",
    "plt.plot(results.history['mean_iou'])\n",
    "plt.plot(results.history['val_mean_iou'])\n",
    "plt.title('Model IOU')\n",
    "plt.ylabel('IOU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.savefig('Model_IOU.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_prediction1(data,cmaps,label_names=None):\n",
    "    data_shape = np.array(data).shape\n",
    "    numImageTypes = data_shape[0]\n",
    "    numImageSets = data_shape[1]\n",
    "    print(numImageTypes,numImageSets)\n",
    "    fig = plt.figure(figsize=(3*numImageTypes,3*numImageSets))\n",
    "    for i in range(numImageSets):\n",
    "        for j in range(numImageTypes):\n",
    "            ax = plt.subplot(numImageSets, numImageTypes,i*numImageTypes + j+1)\n",
    "            if not label_names==None:\n",
    "                ax.set_title(label_names[j])\n",
    "            plt.axis('off')\n",
    "            img = plt.imshow(data[j][i])\n",
    "            img.set_cmap(cmaps[j])\n",
    "    plt.savefig('prediction_display1.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_data_prediction2(data,cmaps,label_names=None):\n",
    "    data_shape = np.array(data).shape\n",
    "    numImageTypes = data_shape[0]\n",
    "    numImageSets = data_shape[1]\n",
    "    print(numImageTypes,numImageSets)\n",
    "    fig = plt.figure(figsize=(3*numImageTypes,3*numImageSets))\n",
    "    for i in range(numImageSets):\n",
    "        for j in range(numImageTypes):\n",
    "            ax = plt.subplot(numImageSets, numImageTypes,i*numImageTypes + j+1)\n",
    "            if not label_names==None:\n",
    "                ax.set_title(label_names[j])\n",
    "            plt.axis('off')\n",
    "            img = plt.imshow(data[j][i])\n",
    "            img.set_cmap(cmaps[j])\n",
    "    plt.savefig('prediction_display2.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ground truth and prediction  as npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def one_hot_decoding_max(encodings,labels): #choose class with highest probability\n",
    "    decoded = []\n",
    "    labels_with_bg = [0] + labels\n",
    "    for img in encodings:\n",
    "        if (len(img.shape)!=3):\n",
    "            print(\"ERROR: wrong shape\")\n",
    "        original_shape = (img.shape[0],img.shape[1])\n",
    "        img2 = np.argmax(img,axis=2)\n",
    "        img3 = numpy.zeros_like(img2)\n",
    "        for i,label in enumerate(labels_with_bg):\n",
    "            img3 = np.where(img2==i, label, img3)\n",
    "        decoded.append(img3)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ys_undec = one_hot_decoding_max(test_ys,labels_to_keep)  # prediction\n",
    "test_y_undec  = one_hot_decoding(test_y,labels_to_keep)       # ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(np.array(test_x).astype(float))\n",
    "predictions = test_ys_undec\n",
    "groundtruths = test_y_undec\n",
    "input_tests   = test_x\n",
    "print('Total number of predictions: ' +str(len(test_ys_undec)))\n",
    "print('Total number of ground truth: ' +str(len(test_y_undec)))\n",
    "print('Total number of input scans test files: ' +str(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract predictions and ground truth \n",
    "\n",
    "# \n",
    "pred_to_save  = []\n",
    "gt_to_save    = []\n",
    "input_to_save = []\n",
    "\n",
    "#\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_to_save.append(pred)\n",
    "    \n",
    "for j, gt in enumerate(groundtruths):\n",
    "    gt_to_save.append(gt)\n",
    "    \n",
    "for k, test in enumerate(input_tests):\n",
    "    input_to_save.append(test)\n",
    "    \n",
    "    \n",
    "# saving path\n",
    "path = '../models/base_model/'\n",
    "    \n",
    "# save predictions with pickle to model directory\n",
    "pred_file = os.path.join(path, 'preds.npy')\n",
    "pickle.dump(pred_to_save, open(pred_file,\"wb\"))\n",
    "\n",
    "# save ground truth with pickle to model directory\n",
    "gt_file = os.path.join(path, 'gts.npy')\n",
    "pickle.dump(gt_to_save, open(gt_file, \"wb\"))\n",
    "\n",
    "# save inputs with pickle to model directory\n",
    "input_file = os.path.join(path, 'inputs.npy')\n",
    "pickle.dump(input_to_save, open(input_file, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ys = model.predict(np.array(test_x).astype(float))\n",
    "\n",
    "def one_hot_decoding_max(encodings,labels): #choose class with highest probability\n",
    "    decoded = []\n",
    "    labels_with_bg = [0] + labels\n",
    "    for img in encodings:\n",
    "        if (len(img.shape)!=3):\n",
    "            print(\"ERROR: wrong shape\")\n",
    "        original_shape = (img.shape[0],img.shape[1])\n",
    "        img2 = np.argmax(img,axis=2)\n",
    "        img3 = numpy.zeros_like(img2)\n",
    "        for i,label in enumerate(labels_with_bg):\n",
    "            img3 = np.where(img2==i, label, img3)\n",
    "        decoded.append(img3)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "test_ys_undec = one_hot_decoding_max(test_ys,labels_to_keep) #prediction\n",
    "test_y_undec = one_hot_decoding(test_y,labels_to_keep) #gt\n",
    "\n",
    "plot_data_prediction1([test_x[:,:,:,0],test_x[:,:,:,1],test_x[:,:,:,2],test_x[:,:,:,3],test_y_undec,test_ys_undec],['gray','gray','gray','gray','gist_ncar','gist_ncar'],label_names=[\"t1\",\"t2\",\"t2s\",\"pd\",\"gt\",\"prediction\"])\n",
    "\n",
    "labels_with_bg = [0] + labels_to_keep\n",
    "\n",
    "print(\"labels_with_bg: \" +str(labels_with_bg))\n",
    "test_ys_list = [test_ys[:,:,:,i] for i in range(len(labels_with_bg))]\n",
    "test_ys_labels = [id_to_label[l] for l in labels_with_bg]\n",
    "\n",
    "print(\"test_ys_labels: \" +str(test_ys_labels))\n",
    "colour_maps = ['hot' for i in range(len(labels_with_bg))]\n",
    "plot_data_prediction2(test_ys_list,colour_maps,label_names=test_ys_labels)\n",
    "\n",
    "#plot_data([test_ys[:,:,:,0],test_ys[:,:,:,1],test_ys[:,:,:,2],test_ys[:,:,:,3],test_ys[:,:,:,4],test_ys[:,:,:,5]],['hot','hot','hot','hot','hot','hot'],label_names=[\"bg\",\"intima\",\"atheromatous\",\"hem\",\"calc\",\"lumen\"])\n",
    "#print(test_ys_undec[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
